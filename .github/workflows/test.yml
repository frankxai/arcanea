name: Arcanea Test Suite

on:
  push:
    branches: [main, master, develop]
    paths:
      - '**.js'
      - '**.py'
      - '**.html'
      - 'package.json'
      - 'package-lock.json'
      - 'requirements.txt'
      - '.github/workflows/test.yml'
  pull_request:
    branches: [main, master, develop]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Unit Tests (JavaScript)
  unit-tests-js:
    name: JavaScript Unit Tests
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18.x, 20.x]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm install -g jest jest-junit
      
      - name: Run unit tests
        run: npm run test:coverage
        env:
          CI: true
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: jest-test-results-${{ matrix.node-version }}
          path: |
            reports/junit.xml
            coverage/
          retention-days: 30
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: matrix.node-version == '20.x'
        with:
          files: ./coverage/lcov.info
          flags: unittests
          name: javascript-coverage
          fail_ci_if_error: true

  # Integration Tests (Python)
  integration-tests-py:
    name: Python Integration Tests
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-asyncio pytest-cov pytest-html
          pip install aiohttp requests
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      
      - name: Run integration tests
        run: |
          pytest tests/integration/ -v --cov=. --cov-report=xml --cov-report=html -m "not skip"
        env:
          CI: true
          PYTHONPATH: .
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pytest-results-${{ matrix.python-version }}
          path: |
            coverage/python/
            coverage/coverage.xml
            reports/
          retention-days: 30
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: matrix.python-version == '3.11'
        with:
          files: ./coverage/coverage.xml
          flags: integration
          name: python-coverage
          fail_ci_if_error: false

  # E2E Tests (Playwright)
  e2e-tests:
    name: E2E Tests (Playwright)
    runs-on: ubuntu-latest
    needs: [unit-tests-js, integration-tests-py]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
      
      - name: Start dev server
        run: |
          npm run dev &
          npx wait-on http://localhost:3000 --timeout 60000
        env:
          CI: true
      
      - name: Run E2E tests
        run: npx playwright test
        env:
          CI: true
      
      - name: Upload Playwright results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-results
          path: |
            playwright-report/
            test-results/
          retention-days: 30
      
      - name: Upload test screenshots
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: playwright-screenshots
          path: test-results/
          retention-days: 7

  # Code Quality Checks
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run ESLint
        run: |
          if grep -q "eslint" package.json; then
            npm run lint || true
          fi
      
      - name: Check code formatting
        run: |
          if grep -q "prettier" package.json; then
            npm run format:check || true
          fi
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Python linting
        run: |
          pip install flake8 black
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true
          black --check . || true

  # Security Scan
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Run npm audit
        run: |
          npm audit --audit-level=high || true
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # Build Test
  build-test:
    name: Build Verification
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build project
        run: |
          if grep -q "build" package.json; then
            npm run build
          fi
        env:
          CI: true
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: build-failure-logs
          path: |
            .next/
            dist/
            build/
          retention-days: 7

  # Test Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests-js, integration-tests-py, e2e-tests]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-results
      
      - name: Generate test summary
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.unit-tests-js.result }}" == "success" ]; then
            echo "| JavaScript Unit Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| JavaScript Unit Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.integration-tests-py.result }}" == "success" ]; then
            echo "| Python Integration Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Python Integration Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
            echo "| E2E Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| E2E Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const message = `## ğŸ§ª Test Results
            
            | Test Suite | Status |
            |------------|--------|
            | JavaScript Unit Tests | ${{ needs.unit-tests-js.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |
            | Python Integration Tests | ${{ needs.integration-tests-py.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |
            | E2E Tests | ${{ needs.e2e-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |
            
            View detailed results in the [Actions tab](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}).`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: message
            });

  # Coverage Report
  coverage-report:
    name: Coverage Report
    runs-on: ubuntu-latest
    needs: [unit-tests-js, integration-tests-py]
    if: always()
    
    steps:
      - name: Download coverage reports
        uses: actions/download-artifact@v4
        with:
          path: coverage-reports
      
      - name: Upload to Codecov
        uses: codecov/codecov-action@v3
        with:
          fail_ci_if_error: false
          verbose: true
